{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Laiba Aslam\\AppData\\Local\\Temp\\ipykernel_11384\\642718035.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data = pd.read_json('E:\\Post ADP\\Capstone Project\\FYP\\datasets\\Cleaned_data_tokenized.json')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('E:\\Post ADP\\Capstone Project\\FYP\\datasets\\Cleaned_data_tokenized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = data['Review Text']\n",
    "review_title = data['Review Title']\n",
    "description = data['Description']\n",
    "avg_rating = data['Average Rating']\n",
    "features = data['Features']\n",
    "Category = data['Category']\n",
    "review_rating = data['Review Rating']\n",
    "review_date = data['Review Date']\n",
    "review_helpfulvote = data['Review helpful vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    using, Ninja, Call, Pro, Plus, smartwatch, mus...\n",
      "1    using, Ninja, Call, Pro, Plus, smartwatch, mus...\n",
      "2    Overall, product, good, two, things, would, li...\n",
      "3    Affordable, come, variety, features, including...\n",
      "4    call, functionality, seamless, clear, audio, e...\n",
      "Name: Review Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(review_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                ASIN  sentiment_score  \\\n",
      "0  0        B0BF57RN3K\n",
      "1        B0BF57RN3K\n",
      "2     ...           0.9977   \n",
      "1  0        B0BF57RN3K\n",
      "1        B0BF57RN3K\n",
      "2     ...           0.9976   \n",
      "2  0        B0BF57RN3K\n",
      "1        B0BF57RN3K\n",
      "2     ...           0.9783   \n",
      "3  0        B0BF57RN3K\n",
      "1        B0BF57RN3K\n",
      "2     ...           0.9153   \n",
      "4  0        B0BF57RN3K\n",
      "1        B0BF57RN3K\n",
      "2     ...           0.9913   \n",
      "\n",
      "   Positive_score  negative_score  neutral_score sentiment  subjectivity  \\\n",
      "0           0.296           0.000          0.704  Positive      0.542291   \n",
      "1           0.318           0.000          0.682  Positive      0.553212   \n",
      "2           0.301           0.024          0.676  Positive      0.408642   \n",
      "3           0.239           0.095          0.666  Positive      0.529396   \n",
      "4           0.454           0.000          0.546  Positive      0.372467   \n",
      "\n",
      "   Negative_Count  Positive_Count  Articles  ...  Verb  Adverb  Pronoun  \\\n",
      "0               3              31         0  ...     3       1        0   \n",
      "1               2              28         0  ...     2       1        0   \n",
      "2               3               9         0  ...     0       0        0   \n",
      "3               3               8         0  ...     1       0        0   \n",
      "4               1               9         0  ...     0       0        0   \n",
      "\n",
      "   Word_Count  Unique_words  Review_Length  review_date  \\\n",
      "0         259           178           2090   2024-10-14   \n",
      "1         226           165           1845   2024-10-19   \n",
      "2          81            65            629   2024-10-25   \n",
      "3          71            53            619   2024-10-19   \n",
      "4          68            66            573   2024-10-18   \n",
      "\n",
      "   similarity_with_description   similarity_with_features  \\\n",
      "0                      0.397583                       0.0   \n",
      "1                      0.400460                       0.0   \n",
      "2                      0.287669                       0.0   \n",
      "3                      0.286825                       0.0   \n",
      "4                      0.282626                       0.0   \n",
      "\n",
      "   similarity_with_category  \n",
      "0                  0.044481  \n",
      "1                  0.038145  \n",
      "2                  0.030418  \n",
      "3                  0.069602  \n",
      "4                  0.030206  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert text into numerical form (bag of words model)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "matrix = vectorizer.fit_transform(review_text, review_title)\n",
    "\n",
    "extracted_features = []\n",
    "\n",
    "for i, row in data.iterrows(): \n",
    "    reviewText = row['Review Text'].lower()\n",
    "    reviewTitle = row['Review Title']\n",
    "    review_date = row['Review Date']\n",
    "    \n",
    "    merged_review = reviewTitle + \". \" + reviewText\n",
    "    features = {}\n",
    "    # Polarity and subjectivity analysis (TextBlob model)\n",
    "    Sentiment = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = Sentiment.polarity_scores(merged_review)\n",
    "    features['sentiment_score'] = sentiment_score['compound']\n",
    "    positive_score = sentiment_score['pos']\n",
    "    negative_score = sentiment_score['neg']\n",
    "    neutral_score = sentiment_score['neu']\n",
    "    features['Positive_score'] = positive_score\n",
    "    features['negative_score'] = negative_score\n",
    "    features['neutral_score'] = neutral_score\n",
    "\n",
    "    if negative_score > positive_score:\n",
    "        features['sentiment'] = 'Negative'\n",
    "    elif positive_score > negative_score:\n",
    "        features['sentiment'] = 'Positive'\n",
    "    else:\n",
    "        features['sentiment'] = 'Neutral'\n",
    "    testimonial = TextBlob(merged_review)\n",
    "    features['subjectivity'] = testimonial.sentiment.subjectivity\n",
    "    \n",
    "    # Word-level sentiment analysis\n",
    "    neg_word_count = 0\n",
    "    pos_word_count = 0\n",
    "    words = merged_review.split()\n",
    "    for word in words:\n",
    "        word_polarity = TextBlob(word).sentiment.polarity\n",
    "        if word_polarity < 0:\n",
    "            neg_word_count += 1\n",
    "        elif word_polarity > 0:\n",
    "            pos_word_count += 1\n",
    "    features['Negative_Count'] = neg_word_count\n",
    "    features['Positive_Count'] = pos_word_count\n",
    "\n",
    "    #  Count the Articles and negations \n",
    "    articles = ['a', 'an', 'the']\n",
    "    negations = ['no', 'not', 'none', 'nobody', 'nothing',\n",
    "                 'neither', 'nowhere', 'never', 'hardly', 'barely', 'scarcely']\n",
    "    \n",
    "    Art = Nega = 0\n",
    "    for w in words:\n",
    "        if w in articles:\n",
    "            Art += 1\n",
    "        elif w in negations:\n",
    "            Nega += 1\n",
    "    features['Articles'] = Art\n",
    "    features['Negations'] = Nega\n",
    "\n",
    "    # Count the noun, adjective, verb, adverb, pronoun, unique words, word count, review length and authenticity score\n",
    "\n",
    "    Noun = Adj = Verb = Adv = Pro = 0\n",
    "    tags = pos_tag(words)\n",
    "    counts = Counter(tag for word, tag in tags)\n",
    "\n",
    "    Noun += sum([counts[i] for i in counts.keys() if 'NN' in i])\n",
    "    Adj += sum([counts[i] for i in counts.keys() if 'JJ' in i])\n",
    "    Verb += sum([counts[i] for i in counts.keys() if 'VB' in i])\n",
    "    Adv += sum([counts[i] for i in counts.keys() if 'RB' in i])\n",
    "    Pro += sum([counts[i] for i in counts.keys() if (('PRP' in i) or ('PRP$' in i) or ('WP' in i) or ('WP$' in i))])\n",
    "    unique_words_count = len(set(words))\n",
    "    word_count = len(words)\n",
    "    review_length = len(merged_review)\n",
    "\n",
    "    if word_count > 0:\n",
    "        authenticity_score = (Pro + unique_words_count - neg_word_count) / word_count\n",
    "    else:\n",
    "        authenticity_score = 0 \n",
    "\n",
    "    features['Authenticity'] = authenticity_score\n",
    "    features['Noun'] = Noun\n",
    "    features['Adjectives'] = Adj\n",
    "    features['Verb'] = Verb\n",
    "    features['Adverb'] = Adv\n",
    "    features['Pronoun'] = Pro\n",
    "    features['Word_Count'] = word_count\n",
    "    features['Unique_words'] = unique_words_count\n",
    "    features['Review_Length'] = review_length\n",
    "\n",
    "    features['review_date'] = datetime.strptime(review_date, \"%d-%b-%y\")\n",
    "    extracted_features.append(features)\n",
    "\n",
    "    # print(review_timestamp)\n",
    "features_data = pd.DataFrame(extracted_features)\n",
    "\n",
    "# measure the similarity (TF-IDF and Cosine Similarity)\n",
    "\n",
    "def calculate_similarity(matrix1, matrix2, chunk_size=1000):\n",
    "    num_rows = matrix1.shape[0]\n",
    "    similarity_scores = np.zeros(num_rows)\n",
    "    \n",
    "    for start_idx in range(0, num_rows, chunk_size):\n",
    "        end_idx = min(start_idx + chunk_size, num_rows)\n",
    "        chunk_similarity = cosine_similarity(matrix1[start_idx:end_idx], matrix2).max(axis=1)\n",
    "        similarity_scores[start_idx:end_idx] = chunk_similarity\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "tfidf_reviews = tfidf_vectorizer.fit_transform(review_text)\n",
    "tfidf_description = tfidf_vectorizer.transform(description)\n",
    "tfidf_features = tfidf_vectorizer.transform(features)\n",
    "tfidf_categories = tfidf_vectorizer.transform(Category)\n",
    "\n",
    "features_data['similarity_with_description ']= calculate_similarity(tfidf_reviews, tfidf_description)\n",
    "features_data['similarity_with_features'] = calculate_similarity(tfidf_reviews, tfidf_features)\n",
    "features_data['similarity_with_category'] = calculate_similarity(tfidf_reviews, tfidf_categories)\n",
    "# features_data['Review_Text'] = review_text\n",
    "\n",
    "\n",
    "print(features_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_reviews_per_day = features_data.groupby('review_date')['Review_Text'].count()\n",
    "\n",
    "# threshold = 20\n",
    "\n",
    "# suspicious = no_of_reviews_per_day[no_of_reviews_per_day > threshold]\n",
    "\n",
    "# features_data['is_suspicious'] = features_data['review_date'].isin(suspicious.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete! Processed file saved as: extractedFeatures.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"extractedFeatures.csv\"\n",
    "features_data.to_csv(output_file_path)\n",
    "\n",
    "print(\"Feature extraction complete! Processed file saved as:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
