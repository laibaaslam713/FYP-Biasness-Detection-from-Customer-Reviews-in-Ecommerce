{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy.linalg import norm\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Laiba Aslam\\AppData\\Local\\Temp\\ipykernel_6772\\642718035.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data = pd.read_json('E:\\Post ADP\\Capstone Project\\FYP\\datasets\\Cleaned_data_tokenized.json')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('E:\\Post ADP\\Capstone Project\\FYP\\datasets\\Cleaned_data_tokenized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = data['Review Text']\n",
    "review_title = data['Review Title']\n",
    "description = data['Description']\n",
    "avg_rating = data['Average Rating']\n",
    "features = data['Features']\n",
    "Category = data['Category']\n",
    "review_rating = data['Review Rating']\n",
    "review_date = data['Review Date']\n",
    "review_helpfulvote = data['Review helpful vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    using, Ninja, Call, Pro, Plus, smartwatch, mus...\n",
      "1    using, Ninja, Call, Pro, Plus, smartwatch, mus...\n",
      "2    Overall, product, good, two, things, would, li...\n",
      "3    Affordable, come, variety, features, including...\n",
      "4    call, functionality, seamless, clear, audio, e...\n",
      "Name: Review Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(review_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1: {m1.shape}, m2: {m2.shape}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'coo_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 122\u001b[0m\n\u001b[0;32m    118\u001b[0m tfidf_features \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(features)\n\u001b[0;32m    119\u001b[0m tfidf_categories \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(Category)\n\u001b[1;32m--> 122\u001b[0m features_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_with_description\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_reviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m features_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_with_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_similarity(tfidf_reviews, tfidf_features)\n\u001b[0;32m    124\u001b[0m features_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_with_category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_similarity(tfidf_reviews, tfidf_categories)\n",
      "Cell \u001b[1;32mIn[17], line 109\u001b[0m, in \u001b[0;36mcalculate_similarity\u001b[1;34m(m1, m2, chunk_size)\u001b[0m\n\u001b[0;32m    107\u001b[0m     chunk_similarity  \u001b[38;5;241m=\u001b[39m m1[start_idx:end_idx]\u001b[38;5;241m.\u001b[39mdot(m2\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# chunk_similarity = cosine_similarity(m1[start_idx:end_idx], m2).max(axis=1)\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[43msimilarity_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m chunk_similarity\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity_scores\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'coo_matrix'"
     ]
    }
   ],
   "source": [
    "# convert text into numerical form (bag of words model)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "matrix = vectorizer.fit_transform(review_text, review_title)\n",
    "\n",
    "extracted_features = []\n",
    "\n",
    "for i, row in data.iterrows(): \n",
    "    reviewText = row['Review Text'].lower()\n",
    "    reviewTitle = row['Review Title']\n",
    "    review_date = row['Review Date']\n",
    "    \n",
    "    merged_review = reviewTitle + \". \" + reviewText\n",
    "    features = {}\n",
    "    # Polarity and subjectivity analysis (TextBlob model)\n",
    "    Sentiment = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = Sentiment.polarity_scores(merged_review)\n",
    "    features['sentiment_score'] = sentiment_score['compound']\n",
    "    positive_score = sentiment_score['pos']\n",
    "    negative_score = sentiment_score['neg']\n",
    "    neutral_score = sentiment_score['neu']\n",
    "    features['Positive_score'] = positive_score\n",
    "    features['negative_score'] = negative_score\n",
    "    features['neutral_score'] = neutral_score\n",
    "\n",
    "    if negative_score > positive_score:\n",
    "        features['sentiment'] = 'Negative'\n",
    "    elif positive_score > negative_score:\n",
    "        features['sentiment'] = 'Positive'\n",
    "    else:\n",
    "        features['sentiment'] = 'Neutral'\n",
    "    testimonial = TextBlob(merged_review)\n",
    "    features['subjectivity'] = testimonial.sentiment.subjectivity\n",
    "    \n",
    "    # Word-level sentiment analysis\n",
    "    neg_word_count = 0\n",
    "    pos_word_count = 0\n",
    "    words = merged_review.split()\n",
    "    for word in words:\n",
    "        word_polarity = TextBlob(word).sentiment.polarity\n",
    "        if word_polarity < 0:\n",
    "            neg_word_count += 1\n",
    "        elif word_polarity > 0:\n",
    "            pos_word_count += 1\n",
    "    features['Negative_Count'] = neg_word_count\n",
    "    features['Positive_Count'] = pos_word_count\n",
    "\n",
    "    #  Count the Articles and negations \n",
    "    articles = ['a', 'an', 'the']\n",
    "    negations = ['no', 'not', 'none', 'nobody', 'nothing',\n",
    "                 'neither', 'nowhere', 'never', 'hardly', 'barely', 'scarcely']\n",
    "    \n",
    "    Art = Nega = 0\n",
    "    for w in words:\n",
    "        if w in articles:\n",
    "            Art += 1\n",
    "        elif w in negations:\n",
    "            Nega += 1\n",
    "    features['Articles'] = Art\n",
    "    features['Negations'] = Nega\n",
    "\n",
    "    # Count the noun, adjective, verb, adverb, pronoun, unique words, word count, review length and authenticity score\n",
    "\n",
    "    Noun = Adj = Verb = Adv = Pro = 0\n",
    "    tags = pos_tag(words)\n",
    "    counts = Counter(tag for word, tag in tags)\n",
    "\n",
    "    Noun += sum([counts[i] for i in counts.keys() if 'NN' in i])\n",
    "    Adj += sum([counts[i] for i in counts.keys() if 'JJ' in i])\n",
    "    Verb += sum([counts[i] for i in counts.keys() if 'VB' in i])\n",
    "    Adv += sum([counts[i] for i in counts.keys() if 'RB' in i])\n",
    "    Pro += sum([counts[i] for i in counts.keys() if (('PRP' in i) or ('PRP$' in i) or ('WP' in i) or ('WP$' in i))])\n",
    "    unique_words_count = len(set(words))\n",
    "    word_count = len(words)\n",
    "    review_length = len(merged_review)\n",
    "\n",
    "    if word_count > 0:\n",
    "        authenticity_score = (Pro + unique_words_count - neg_word_count) / word_count\n",
    "    else:\n",
    "        authenticity_score = 0 \n",
    "\n",
    "    features['Authenticity'] = authenticity_score\n",
    "    features['Noun'] = Noun\n",
    "    features['Adjectives'] = Adj\n",
    "    features['Verb'] = Verb\n",
    "    features['Adverb'] = Adv\n",
    "    features['Pronoun'] = Pro\n",
    "    features['Word_Count'] = word_count\n",
    "    features['Unique_words'] = unique_words_count\n",
    "    features['Review_Length'] = review_length\n",
    "\n",
    "    features['review_date'] = datetime.strptime(review_date, \"%d-%b-%y\")\n",
    "    extracted_features.append(features)\n",
    "\n",
    "    # print(review_timestamp)\n",
    "features_data = pd.DataFrame(extracted_features)\n",
    "\n",
    "# measure the similarity (TF-IDF and Cosine Similarity)\n",
    "\n",
    "def calculate_similarity(m1, m2, chunk_size=1000):\n",
    "    print(\"m1: {m1.shape}, m2: {m2.shape}\")\n",
    "    num_rows = m1.shape[0]\n",
    "    similarity_scores = np.zeros(num_rows)\n",
    "    \n",
    "    for start_idx in range(0, num_rows, chunk_size):\n",
    "        end_idx = min(start_idx + chunk_size, num_rows)\n",
    "        # chunk_similarity = np.dot(m1[start_idx:end_idx], m2.T)/norm(m1[start_idx:end_idx])*norm(m2)\n",
    "        chunk_similarity  = m1[start_idx:end_idx].dot(m2.T)\n",
    "        # chunk_similarity = cosine_similarity(m1[start_idx:end_idx], m2).max(axis=1)\n",
    "        similarity_scores[start_idx:end_idx] = chunk_similarity.toarray().max(axis=1)\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "\n",
    "tfidf_reviews = tfidf_vectorizer.fit_transform(review_text)\n",
    "tfidf_description = tfidf_vectorizer.transform(description)\n",
    "tfidf_features = tfidf_vectorizer.transform(features)\n",
    "tfidf_categories = tfidf_vectorizer.transform(Category)\n",
    "\n",
    "\n",
    "features_data['similarity_with_description'] = calculate_similarity(tfidf_reviews, tfidf_description)\n",
    "features_data['similarity_with_features'] = calculate_similarity(tfidf_reviews, tfidf_features)\n",
    "features_data['similarity_with_category'] = calculate_similarity(tfidf_reviews, tfidf_categories)\n",
    "\n",
    "\n",
    "# features_data['similarity_with_description']= calculate_similarity(tfidf_reviews, tfidf_description)\n",
    "# features_data['similarity_with_features'] = calculate_similarity(tfidf_reviews, tfidf_features)\n",
    "# features_data['similarity_with_category'] = calculate_similarity(tfidf_reviews, tfidf_categories)\n",
    "# features_data['Review_Text'] = review_text\n",
    "\n",
    "\n",
    "print(features_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Overlap: set()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_vectorizer.fit(review_text)\n",
    "# Get the vocabulary of the vectorizer\n",
    "vocab = set(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Check overlap between review_text and features vocabulary\n",
    "review_words = set(\" \".join(review_text).split())\n",
    "features_words = set(\" \".join(features).split())\n",
    "\n",
    "overlap = vocab & features_words\n",
    "print(\"Vocabulary Overlap:\", overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_reviews_per_day = features_data.groupby('review_date')['Review_Text'].count()\n",
    "\n",
    "# threshold = 20\n",
    "\n",
    "# suspicious = no_of_reviews_per_day[no_of_reviews_per_day > threshold]\n",
    "\n",
    "# features_data['is_suspicious'] = features_data['review_date'].isin(suspicious.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete! Processed file saved as: extractedFeatures_data.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"extractedFeatures_data.csv\"\n",
    "features_data.to_csv(output_file_path)\n",
    "\n",
    "print(\"Feature extraction complete! Processed file saved as:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
