{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Laiba Aslam\\AppData\\Local\\Temp\\ipykernel_10772\\1331875547.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data = pd.read_json('E:\\Post ADP\\Capstone Project\\Scrapping from Amazon\\FYP\\datasets\\Cleaned_data_tokenized.json')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('E:\\Post ADP\\Capstone Project\\Scrapping from Amazon\\FYP\\datasets\\Cleaned_data_tokenized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = data['Review Text']\n",
    "review_title = data['Review Title']\n",
    "description = data['Description']\n",
    "avg_rating = data['Average Rating']\n",
    "features = data['Features']\n",
    "Category = data['Category']\n",
    "review_rating = data['Review Rating']\n",
    "review_date = data['Review Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    using, Ninja, Call, Pro, Plus, smartwatch, mus...\n",
      "1    using, Ninja, Call, Pro, Plus, smartwatch, mus...\n",
      "2    Overall, product, good, two, things, would, li...\n",
      "3    Affordable, come, variety, features, including...\n",
      "4    call, functionality, seamless, clear, audio, e...\n",
      "Name: Review Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(review_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment  subjectivity  Negative_Count  Positive_Count  Articles  \\\n",
      "0   0.246733      0.542487               2              30         0   \n",
      "1   0.244881      0.550375               2              27         0   \n",
      "2   0.179412      0.373856               3               8         0   \n",
      "3   0.264286      0.523512               3               7         0   \n",
      "4   0.260659      0.331888               1               8         0   \n",
      "\n",
      "   Negations  Authenticity  Noun  Adjectives  Verb  Adverb  Word_Count  \\\n",
      "0          0      0.669323   231          12     3       1         251   \n",
      "1          0      0.718750   207          11     2       1         224   \n",
      "2          0      0.779221    76           1     0       0          77   \n",
      "3          0      0.695652    68           1     0       0          69   \n",
      "4          0      0.955224    64           3     0       0          67   \n",
      "\n",
      "   Unique_words  Review_Length  similarity_with_description   \\\n",
      "0           170           2037                      0.397583   \n",
      "1           163           1822                      0.400460   \n",
      "2            63            595                      0.287669   \n",
      "3            51            607                      0.286825   \n",
      "4            65            564                      0.282626   \n",
      "\n",
      "   similarity_with_features  similarity_with_category  \\\n",
      "0                       0.0                  0.044481   \n",
      "1                       0.0                  0.038145   \n",
      "2                       0.0                  0.030418   \n",
      "3                       0.0                  0.069602   \n",
      "4                       0.0                  0.030206   \n",
      "\n",
      "                                         Review_Text  \n",
      "0  using, Ninja, Call, Pro, Plus, smartwatch, mus...  \n",
      "1  using, Ninja, Call, Pro, Plus, smartwatch, mus...  \n",
      "2  Overall, product, good, two, things, would, li...  \n",
      "3  Affordable, come, variety, features, including...  \n",
      "4  call, functionality, seamless, clear, audio, e...  \n"
     ]
    }
   ],
   "source": [
    "# convert text into numerical form (bag of words model)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "matrix = vectorizer.fit_transform(review_text, review_title)\n",
    "\n",
    "extracted_features = []\n",
    "\n",
    "for i, row in data.iterrows(): \n",
    "    review = row[\"Review Text\"].lower()  \n",
    "    \n",
    "\n",
    "    features = {}\n",
    "    # Polarity and subjectivity analysis (TextBlob model)\n",
    "    testimonial = TextBlob(review)\n",
    "    polarity = testimonial.sentiment.polarity\n",
    "    features['polarity'] = polarity\n",
    "    features['subjectivity'] = testimonial.sentiment.subjectivity\n",
    "    \n",
    "    # Word-level sentiment analysis\n",
    "    neg_word_count = 0\n",
    "    pos_word_count = 0\n",
    "    words = review.split()\n",
    "    for word in words:\n",
    "        word_polarity = TextBlob(word).sentiment.polarity\n",
    "        if word_polarity < 0:\n",
    "            neg_word_count += 1\n",
    "        elif word_polarity > 0:\n",
    "            pos_word_count += 1\n",
    "    features['Negative_Count'] = neg_word_count\n",
    "    features['Positive_Count'] = pos_word_count\n",
    "\n",
    "    #  Count the Articles and negations \n",
    "    articles = ['a', 'an', 'the']\n",
    "    negations = ['no', 'not', 'none', 'nobody', 'nothing',\n",
    "                 'neither', 'nowhere', 'never', 'hardly', 'barely', 'scarcely']\n",
    "    \n",
    "    Art = Nega = 0\n",
    "    for w in words:\n",
    "        if w in articles:\n",
    "            Art += 1\n",
    "        elif w in negations:\n",
    "            Nega += 1\n",
    "    features['Articles'] = Art\n",
    "    features['Negations'] = Nega\n",
    "\n",
    "    # Count the noun, adjective, verb, adverb, pronoun, unique words, word count, review length and authenticity score\n",
    "\n",
    "    Noun = Adj = Verb = Adv = Pro = 0\n",
    "    tags = pos_tag(words)\n",
    "    counts = Counter(tag for word, tag in tags)\n",
    "\n",
    "    Noun += sum([counts[i] for i in counts.keys() if 'NN' in i])\n",
    "    Adj += sum([counts[i] for i in counts.keys() if 'JJ' in i])\n",
    "    Verb += sum([counts[i] for i in counts.keys() if 'VB' in i])\n",
    "    Adv += sum([counts[i] for i in counts.keys() if 'RB' in i])\n",
    "    Pro += sum([counts[i] for i in counts.keys() if (('PRP' in i) or ('PRP$' in i) or ('WP' in i) or ('WP$' in i))])\n",
    "    unique_words_count = len(set(words))\n",
    "    word_count = len(words)\n",
    "    review_length = len(review)\n",
    "\n",
    "    if word_count > 0:\n",
    "        authenticity_score = (Pro + unique_words_count - neg_word_count) / word_count\n",
    "    else:\n",
    "        authenticity_score = 0 \n",
    "\n",
    "    features['Authenticity'] = authenticity_score\n",
    "    features['Noun'] = Noun\n",
    "    features['Adjectives'] = Adj\n",
    "    features['Verb'] = Verb\n",
    "    features['Adverb'] = Adv\n",
    "    features['Pronoun'] = Pro\n",
    "    features['Word_Count'] = word_count\n",
    "    features['Unique_words'] = unique_words_count\n",
    "    features['Review_Length'] = review_length\n",
    "\n",
    "\n",
    "    extracted_features.append(features)\n",
    "\n",
    "features_data = pd.DataFrame(extracted_features)\n",
    "\n",
    "# 5. measure the similarity (TF-IDF and Cosine Similarity)\n",
    "\n",
    "def calculate_similarity(m1, m2, chunk_size=1000):\n",
    "    num_rows = m1.shape[0]\n",
    "    similarity_scores = np.zeros(num_rows)\n",
    "    \n",
    "    for start_idx in range(0, num_rows, chunk_size):\n",
    "        end_idx = min(start_idx + chunk_size, num_rows)\n",
    "        chunk_similarity = cosine_similarity(m1[start_idx:end_idx], m2).max(axis=1)\n",
    "        similarity_scores[start_idx:end_idx] = chunk_similarity\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "tfidf_reviews = tfidf_vectorizer.fit_transform(review_text)\n",
    "tfidf_description = tfidf_vectorizer.transform(description)\n",
    "tfidf_features = tfidf_vectorizer.transform(features)\n",
    "tfidf_categories = tfidf_vectorizer.transform(Category)\n",
    "\n",
    "features_data['similarity_with_description ']= calculate_similarity(tfidf_reviews, tfidf_description)\n",
    "features_data['similarity_with_features'] = calculate_similarity(tfidf_reviews, tfidf_features)\n",
    "features_data['similarity_with_category'] = calculate_similarity(tfidf_reviews, tfidf_categories)\n",
    "features_data['Review_Text'] = review_text\n",
    "\n",
    "\n",
    "print(features_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete! Processed file saved as: processed_data_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"processed_data_with_sentiment.csv\"\n",
    "features_data.to_csv(output_file_path)\n",
    "\n",
    "print(\"Feature extraction complete! Processed file saved as:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
